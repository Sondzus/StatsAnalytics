---
title: "Topic 2: Sampling distribution of the mean"
subtitle: |
  | Background for inference of location parameter in location/scale families
author: |
  | Sonja PetroviÄ‡
  | Created for ITMD/ITMS/STAT 514
date: "Spring 2021." 
urlcolor: darkblue
output: 
  beamer_presentation:
    theme: "CambridgeUS"
    colortheme: "beaver"
    includes:
      in_header: header_beamer.tex
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,comment = '', fig.align = 'center'  , out.width="50%"
)
knitr::include_graphics
```




```{r packages, include=FALSE}
#install.packages("tigerstats")
#install.packages("reticulate")
#devtools::install_github("rstudio/reticulate")
library("tigerstats") # to run the basic rnorm function but with the plot included.
library("reticulate") # to run python code

scipy <- import("scipy") 
# ^^ issues/errors? Here are 3 hints:  
# * have you installed miniconda / anaconda? 
# * have you tried "pip install scipy" in terminal? 
# * have you tried the following 3 lines instead of the line above (comment out line 35, un-comment 40-42):  
#use_condaenv("r-reticulate")
#py_install("scipy", pip = TRUE)
#py_module_available("scipy")
```


# Context 

Statistics: 

* Functions of random variables 
* Therefore, are random variables  themselves.    
  * In particular, they have their own distributions, called \attn{sampling distributions}. 
  * Meaning of sampling distribution **(Review)** 

* How does inference relate to analytics? **(Review)** 

  
\pause 
  
<!-- ![look](https://unsplash.com/photos/uAFjFsMS3YY) -->
<!--Let's look at some examples. -->

![](figures/look.jpeg){ width=10% }


# Do *you* know population variance? 

Recall the random variable which has  a normal distribution by the CLT:
\only<1>{\[Z = \frac{\Xbar-\mu}{\sigma/\sqrt{n}}.\]}
\only<2->{\[Z = \frac{\Xbar-\mu}{\attn{\sigma}/\sqrt{n}}.\]}
\pause
What happens when you do not know $\sigma$? 

\pause 

\redblock{{Question}
What do we know about \[\frac{\Xbar-\mu}{\attn{S}/\sqrt{n}} ?\] 
}

# A comparative simulation: Z
Suppose we just take one sample, $X$, of size $100$ from a normal population with mean $\mu=25$ and standard deviation $\sigma=10$. Here's our friend, the random variable $Z$: 
```{r exploreNormalVsT}
  get.Z.value <- function(sample.size,mu,sigma){
    x <- rnorm(n=sample.size,mean=mu,sd=sigma)
    (mean(x)-mu)/(sigma/sqrt(sample.size))  
  }
```
\redblock{{Notice a **function** up there, in the code?}}
```{r getZfromOneSample}
  my.mu = 25
  my.sigma = 10
  my.sample.size = 100
  get.Z.value(sample.size=my.sample.size,mu=my.mu,sigma = my.sigma)
```


# A comparative simulation: Z

Of course this is just *one* value of the staistic $Z$. Now, repeat!  
\small
```{r exploreNormalVsT-reps}
Z.sampled <- replicate(10,
                       get.Z.value(sample.size=my.sample.size,
                                   mu=my.mu,sigma = my.sigma))
hist(Z.sampled,
     main=paste("Sample size 10, X sample size",my.sample.size),
     xlab="Z")
```
\normalsize 

# A comparative simulation: Z

\small
```{r exploreNormalVsT-reps-4times}
par(mfrow = c(2, 2))
hist(replicate(10,get.Z.value(sample.size=my.sample.size,mu=my.mu,
                  sigma =my.sigma)),main="Sample size 10",xlab="Z")
hist(replicate(10,get.Z.value(sample.size=my.sample.size,mu=my.mu,
                  sigma =my.sigma)),main="Sample size 10",xlab="Z")
hist(replicate(10,get.Z.value(sample.size=my.sample.size,mu=my.mu,
                 sigma =my.sigma)),main="Sample size 10",xlab="Z")
hist(replicate(10,get.Z.value(sample.size=my.sample.size,mu=my.mu,
                  sigma =my.sigma)),main="Sample size 10",xlab="Z")
```

\normalsize 


# A comparative simulation: Z

... What about more reps? 
\small 
```{r exploreNormalVsT-moreReps}
par(mfrow = c(1, 2))
Z.sampled <- replicate(100,get.Z.value(
  sample.size=my.sample.size,mu=my.mu,sigma = my.sigma))
hist(Z.sampled, main="Sample size 100")
Z.sampled <- replicate(1000, get.Z.value(
  sample.size=my.sample.size,mu=my.mu,sigma = my.sigma))
hist(Z.sampled, main="Sample size 1000")
```
\normalsize


# A comparative simulation: T
Now let's replace $\sigma$ by $S$. 
```{r exploreNormalVsT-defineT}
  get.T.value <- function(sample.size, mu, sigma){
    x <- rnorm(n=sample.size,mean=mu,sd=sigma)
    (mean(x)-mu)/(sd(x)/sqrt(sample.size))  
  }
  my.mu = 25
  my.sigma = 10
  my.sample.size = 100
  get.T.value(sample.size=my.sample.size,mu=my.mu,sigma=my.sigma)
```

# A comparative simulation: T

Again, need to repeat: 
\small
```{r exploreNormalVsT-exploreT, out.width="50%"}
par(mfrow = c(1, 2))
T.sampled <- replicate(100, get.T.value(sample.size=my.sample.size,mu=my.mu,sigma = my.sigma))
hist(T.sampled)
Z.sampled <- replicate(100, get.Z.value(sample.size=my.sample.size,mu=my.mu,sigma = my.sigma))
hist(Z.sampled)
```
\normalsize 

# A comparative simulation: the Z vs. T random variable

\small
```{r exploreNormalVsT-Tfattails, out.width="50%", out.height="50%",echo=FALSE}
T.sampled <- replicate(1000, get.T.value(sample.size=my.sample.size,mu=my.mu,sigma=my.sigma))
Z.sampled <- replicate(1000, get.Z.value(sample.size=my.sample.size,mu=my.mu,sigma=my.sigma))
par(mfrow = c(1, 2))
hist(T.sampled)
hist(Z.sampled)
```
\normalsize 
\vspace{-5mm}
\redblock{{Aha!}...What do you see??}
\pause 

\small
<!-- AhaSlides questions: select TRUE from below-->
* The T distribution looks just like Z. Let's use the CLT! \attn{$\leftarrow$??}
* I don't get it. We just replaced $\sigma$ by $S$ so...big deal?? \attn{$\leftarrow$??}
* T is a different random variable than Z. The histograms look similar... but can we prove it's the same shape?? \attn{$\leftarrow$??}


# How do we compare the two sampling distributions? 

One way: let us plot \attn{the $T$ histogram} and overlay the \attn{the $Z$ density curve} on top. 

```{r plotDensityOverHistogram, out.width="50%", out.height="50%",echo=FALSE}
T.sampled <- replicate(50, get.T.value(sample.size=my.sample.size,mu=my.mu,sigma=my.sigma))
h<-hist(T.sampled, breaks=15, xlab="sampled T values",main="Normal curve over histogram, sample size 50")
xfit<-seq(min(T.sampled),max(T.sampled),length=40)
yfit<-dnorm(xfit,mean=mean(T.sampled),sd=sd(T.sampled))
yfit <- yfit*diff(h$mids[1:2])*length(T.sampled)
lines(xfit, yfit, col="blue", lwd=2)
#lines(density(dnorm(x,mean=0,sd=1)),col="darkblue")
# curve(dnorm(x, mean=my.mu, sd=my.sigma), 
  #    col="darkblue", lwd=2, add=TRUE, yaxt="n")
```
\tiny 
\hfill *For HW, you will explore different ways to plot a normal curve over a histogram.
\normalsize 

\redblock{{Why?} Because we \attn{know} the theoretical distribution of $Z$!}




# The $t$ distribution 

\redblock{{Theorem}
Let $X_1,\dots,X_n$ be independent random variables that are \attn{all normal} with
mean $\mu$  and standard deviation $\sigma$. Let $\Xbar$ and $\S^2$ be sample mean and sample standard deviation, respectively. Then 
Then the random variable 
\[ T =\frac{\Xbar-\mu}{\attn{S}/\sqrt{n}}
\]
has a \attn{$t$-}distribution \attn{with $\nu=n-1$ degrees of freedom}. 
}

* What are 'degrees of freedom' and how does $n-1$ change the shape of $T\sim t_{n-1}$? 
* How is this distribution defined? 

> {\small (By the way, have you ever wondered how is the normal $N(\mu,\sigma)$ defined? It's not "just a curve", there's a prob. formula, right?)}

<!-- notes to PROF:
insert pages 246-250 from the engrStat book and go over them in the lecture, to the extent possible.
--> 

--- 

We need some standard notation.

* Discuss: the notation $t_\alpha$. 
* Discuss aslo: the notation $z_\alpha$. 

\pause 
\redblock{{Aha!} Do we get the meaning of these?}
# An example that needs the $t$-distribution computation

<!--\tiny 
here is an example from the book.
compute this and then compare to waht the answr would have been if we coptued the normal tail instead of the t-distribution tail.
-->

## Problem.
> A chemical engineer claims that the population mean yield of a certain batch
process is 500 grams per milliliter of raw material. To check this claim he samples
25 batches each month. If the computed t-value falls between $-t_{0.05}$ and $t_{0.05}$, he
is satisfied with this claim. What conclusion should he draw from a sample that
has a mean $\Xbar = 518$ grams per milliliter and a sample standard deviation $s= 40$
grams? Assume the distribution of yields to be approximately normal.


# An example with $t$ in Python 
\small

```{python}
from scipy.stats import t
mean=518
n=25
s=40
u=500
#computing the t-value from the sample
tvalue=(mean-u)/(s/5)
#computing the t0.5,... remember the degree of freedom is 24
interval=t.cdf(0.5,24)
print(-interval)
print(interval)
print(tvalue)
```
\normalsize

# What is next?

* The F-distribution (...almost the last one!)
* The sampling distribution of $S^2$. 
* Putting it all together, and doing formal statistical tests: 
  - Data scenarios
  - Flowchart: which distribution to use when and why? 
  - Play with examples and test things out in lab work. 
  
\redblock{{Aha!} Let's get started on some basic questions for "what to use when", shall we? :) }


#  License  

This document  is created for ITMD/ITMS/STAT 514, Spring 2021, at Illinois Tech. 

While the course materials are generally not to be distributed outside the course without permission of the instructor, all materials posted on this page are licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-nc-sa/4.0/).